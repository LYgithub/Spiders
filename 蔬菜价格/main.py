## /Users/mac/PycharmProjects # -*- coding: utf-8 -*-# @Time    : 2017/8/23 am 11:31# @Author  : Liyang# @Site    : # @File    : main.py# @Software: PyCharm##"""        该程序是一个定向爬虫        爬取  百度百科科的Python字条中，所有的 英文（目前尚未达到中文水平） 词语的 URL                以及该词语的百度百科解释        如果感觉爬取的内容较多，时间可能较长        包括 URL管理器，HTML下载器，HTML解析器，以及输出器等内容"""# 全局取消证书验证---------------------------------------------------####相关参考http://blog.csdn.net/hshl1214/article/details/52130048import sslssl._create_default_https_context = ssl._create_unverified_context# -----------------------------------------------------------------import URL_jiexi, URL_downloader, html_parserclass PaChong(object):    def __init__(self):        self.downloader = URL_downloader.HTML_downloader()        self.HTML_JieXi = URL_jiexi.JieXi()        self.parser = html_parser.HtmlParse()        # self.data = xinjian.dat_downloader()    def carw(self, root_url):        try:            number = 1            urls = self.HTML_JieXi.URL_jiexi(root_url)            for i in urls:                if number <= 5 and self.parser.has_url(i):                    print("carw:", number, i.name, i["href"], i.get_text())                    self.downloader.URL_downloader(i["href"], i.get_text())                    self.downloader.data_down(i["href"])                    number2 = 1                    url_s = self.HTML_JieXi.URL_jiexi(i["href"])                    for url in url_s:                        if number2 <= 1:  # and self.parser.has_url(url):                            print("\t\t\tcarw:", number, ".", number2, url.name, url["href"], url.get_text())                            self.downloader.URL_downloader(url["href"], url.get_text())                            self.downloader.data_down(url["href"])                            number2 += 1                number += 1        except:            print("fail")if __name__ == "__main__":    # root_url = 'https://baike.baidu.com/item/Python'    root_url = "http://www.shucai123.com/price.php"    xinjan = PaChong()    xinjan.carw(root_url)    print("-------------------------------finish!----------------------------")